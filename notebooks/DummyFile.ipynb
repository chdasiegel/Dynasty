{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aabdf1-326b-4538-bf8d-d823a9405890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/chase/Desktop/Comp_Sci/Capstone/Dynasty\")\n",
    "\n",
    "from src.process_college import build_player_dict\n",
    "\n",
    "player_dict = build_player_dict(verbose=False)\n",
    "print(len(player_dict))\n",
    "print(player_dict.get(\"Cameron Ward\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e9e61-f8c9-4e23-a507-be3786662be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/chase/Desktop/Comp_Sci/Capstone/Dynasty\")\n",
    "\n",
    "from src.process_combine import build_combine_dict\n",
    "\n",
    "player_combine = build_combine_dict(verbose=False)\n",
    "print(len(player_combine))\n",
    "print(player_combine.get(\"Amon-Ra St Brown\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eac278-a380-4867-8a89-8410ff50ccc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.process_pro_qb import run_pro_qb_player\n",
    "\n",
    "qb_dict = run_pro_qb_player(years=range(2016, 2025), s_type=\"REG\", verbose=False)\n",
    "print(len(qb_dict))\n",
    "print(qb_dict.get(\"Patrick Mahomes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b566f-c224-4708-bc51-12aa66289e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process_pro_wr import run_pro_wr_player\n",
    "\n",
    "wr_dict = run_pro_wr_player(years=range(2016, 2025), s_type=\"REG\", verbose=False)\n",
    "print(len(wr_dict))\n",
    "print(wr_dict.get(\"Rashee Rice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b105db8-4934-4516-853b-89d4c51c9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process_pro_rb import run_pro_rb_player\n",
    "\n",
    "rb_dict = run_pro_rb_player(years=range(2016, 2025), s_type=\"REG\", verbose=False)\n",
    "print(len(rb_dict))\n",
    "print(rb_dict.get(\"Christian McCaffrey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd833bc-28cd-4c7b-aa1c-ef181c054503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process_pro_te import run_pro_te_player\n",
    "\n",
    "te_dict = run_pro_te_player(years=range(2016, 2025), s_type=\"REG\", verbose=False)\n",
    "print(len(te_dict))\n",
    "print(te_dict.get(\"Travis Kelce\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16f46e-8b40-40fe-85e0-c18c2a2415d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fantasycalc_client import (\n",
    "        get_player_value, search_players,\n",
    "        get_rankings_df, save_current_rankings\n",
    "    )\n",
    "\n",
    "# Look up one player\n",
    "row = get_player_value(\"Breece Hall\")\n",
    "print(row)\n",
    "\n",
    "# Search for possible name matches\n",
    "print(search_players(\"Harrison\"))\n",
    "\n",
    "# Get full rankings as a DataFrame\n",
    "df = get_rankings_df(dynasty=True, num_qbs=2, teams=12, ppr=1.0)\n",
    "print(df.head())\n",
    "\n",
    "# Save CSV snapshot(s) to Market_Value/\n",
    "path = save_current_rankings(dynasty=True, num_qbs=2, teams=12, ppr=1.0)\n",
    "print(\"Saved:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f8c77-0650-49e6-95aa-78b79e7e458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot_scatter_wr_combine import main\n",
    "main(years=range(2020, 2026), limit=50, pick_min=1, pick_max=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b66bc-f4b8-4615-9aee-c0e1bf6f058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from src.utils import clean_player_name\n",
    "\n",
    "print(clean_player_name(\"Amon-Ra St. Brown\"))   # Amon-Ra StBrown\n",
    "print(clean_player_name(\"amon-ra st brown\"))    # Amon-Ra StBrown\n",
    "print(clean_player_name(None))                  # \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd1074-ddfb-4aae-8090-15a8a7e7f245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c2913-3ce6-433e-b58f-104921f301c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_player_name(player_name):\n",
    "    \"\"\"Clean names while preserving apostrophes/hyphens, fusing 'St. X' -> 'StX',\n",
    "    and normalizing casing to Title Case.\"\"\"\n",
    "    if not isinstance(player_name, str):\n",
    "        return player_name\n",
    "\n",
    "    s = player_name.strip()\n",
    "\n",
    "    # 1) Remove common suffixes (Jr, Sr, II, III, IV, V), case-insensitive\n",
    "    suffixes = ['Jr', 'Sr', 'II', 'III', 'IV', 'V']\n",
    "    s = re.sub(r'\\b(?:' + '|'.join(suffixes) + r')\\b\\.?', '', s, flags=re.IGNORECASE)\n",
    "\n",
    "    # 2) Keep only word chars, whitespace, apostrophes, and hyphens\n",
    "    s = re.sub(r\"[^\\w\\s'-]\", '', s)\n",
    "\n",
    "    # 3) Fuse 'St. ' or 'St ' (any case) before a capitalized surname -> 'StSurname'\n",
    "    s = re.sub(r\"\\bSt[.\\s]+(?=[A-Z])\", \"St\", s, flags=re.IGNORECASE)\n",
    "\n",
    "    # 4) Collapse extra spaces\n",
    "    s = ' '.join(s.split())\n",
    "\n",
    "    # 5) Normalize to Title Case (preserves apostrophes/hyphens properly)\n",
    "    s = s.title()\n",
    "\n",
    "    # Fix common cases where title-casing breaks (e.g., \"O'Neal\" -> \"O'Neal\", not \"O'Neal\")\n",
    "    # The default .title() already does this okay, but just in case:\n",
    "    s = re.sub(r\"\\bO'([A-Z])\", lambda m: \"O'\" + m.group(1).upper(), s)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def strip_name_marks(s: object) -> object:\n",
    "    \"\"\"Strip common extraneous marks like '*' without touching apostrophes or hyphens.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return s.replace(\"*\", \"\")\n",
    "\n",
    "\n",
    "# ---- quick checks ----\n",
    "tests = [\n",
    "    \"Amon-Ra St. Brown\",\n",
    "    \"amon-ra st. brown\",\n",
    "    \"O'Neal Jr.\",\n",
    "    \"jean-baptiste iii\",\n",
    "    \"ST. JOHN\",\n",
    "]\n",
    "for t in tests:\n",
    "    print(t, \"->\", clean_player_name(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cb063-842c-415f-9bf1-4951a8716d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/Bakery/RB/Bakery_RB_2017.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec903649-c891-4226-9ea6-9108bf7a3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# adjust path (this assumes you’re in Dynasty/notebooks/)\n",
    "df = pd.read_csv(\"./data/Bakery/RB/Bakery_RB_2017.csv\")\n",
    "\n",
    "# Clean up column names\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169a4b7-20a2-47be-a7ee-c8988a46e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"DOM++\", \"40 Time\", \"BMI\", \"YPC\",\n",
    "    \"ELU\", \"YCO/A\", \"Break%\", \"Draft Cap\", \"BAMA\"\n",
    "]\n",
    "\n",
    "target = \"RB Grade\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea14265-2f6c-41c4-9d9b-a7a349813c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target]\n",
    "\n",
    "# invert \"lower is better\"\n",
    "X[\"40 Time\"]      = -X[\"40 Time\"]\n",
    "X[\"Draft Cap\"] = -X[\"Draft Cap\"]\n",
    "\n",
    "# drop rows with missing values\n",
    "mask = X.notna().all(axis=1) & y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b35907-65ad-493d-8d0f-bb0046c79595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "weights = pd.Series(model.coef_, index=features).sort_values(ascending=False)\n",
    "print(\"Approximate Weights for RB Grade:\")\n",
    "print(weights)\n",
    "\n",
    "print(\"\\nIntercept:\", model.intercept_)\n",
    "print(\"R² (fit quality):\", round(model.score(X_scaled, y), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f149b-63e6-4a3e-a632-d082b4530b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_pos = Lasso(alpha=0.01, positive=True, max_iter=10000)\n",
    "lasso_pos.fit(X_scaled, y)\n",
    "\n",
    "weights_lasso = pd.Series(lasso_pos.coef_, index=features).sort_values(ascending=False)\n",
    "print(\"Lasso (positive, shrunk weights):\\n\", weights_lasso)\n",
    "print(\"\\nR²:\", round(lasso_pos.score(X_scaled, y), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbda8ad-152f-458e-803e-46e5c986265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_pos = LinearRegression(positive=True)\n",
    "model_pos.fit(X_scaled, y)\n",
    "\n",
    "weights_pos = pd.Series(model_pos.coef_, index=features).sort_values(ascending=False)\n",
    "print(\"Non-Negative Weights:\\n\", weights_pos)\n",
    "print(\"\\nR²:\", round(model_pos.score(X_scaled, y), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2c5c49-8db6-4f1c-8f94-94de4441bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data/Bakery/RB/Bakery_RB_Overall.csv\n",
      "Rows x Cols: (247, 125)\n",
      "\n",
      "Using features (canonical <- sheet column):\n",
      "  DOM++        <- DOM++\n",
      "  40 Time      <- 40 Time\n",
      "  BMI          <- BMI\n",
      "  YPC          <- YPC\n",
      "  ELU          <- ELU\n",
      "  YCO/A        <- YCO/A\n",
      "  Break%       <- Break %\n",
      "  Draft Capital <- Draft Cap\n",
      "  Bama         <- BAMA\n",
      "  Rec Yards    <- Rec Yds\n",
      "Kept features: ['DOM++', '40 Time', 'BMI', 'YPC', 'ELU', 'YCO/A', 'Break%', 'Draft Capital', 'Bama', 'Rec Yards']\n",
      "\n",
      "=== Model comparison (non-negative only) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>w:DOM++</th>\n",
       "      <th>w:40 Time</th>\n",
       "      <th>w:BMI</th>\n",
       "      <th>w:YPC</th>\n",
       "      <th>w:ELU</th>\n",
       "      <th>w:YCO/A</th>\n",
       "      <th>w:Break%</th>\n",
       "      <th>w:Draft Capital</th>\n",
       "      <th>w:Bama</th>\n",
       "      <th>w:Rec Yards</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS_Positive</th>\n",
       "      <td>0.7117</td>\n",
       "      <td>1.3924</td>\n",
       "      <td>0.6178</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>1.0676</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNLS_Positive</th>\n",
       "      <td>0.7117</td>\n",
       "      <td>1.3924</td>\n",
       "      <td>0.6178</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>1.0676</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R2  w:DOM++  w:40 Time  w:BMI  w:YPC   w:ELU  w:YCO/A  \\\n",
       "Model                                                                      \n",
       "OLS_Positive   0.7117   1.3924     0.6178  0.387  0.352  0.8815      0.0   \n",
       "NNLS_Positive  0.7117   1.3924     0.6178  0.387  0.352  0.8815      0.0   \n",
       "\n",
       "               w:Break%  w:Draft Capital  w:Bama  w:Rec Yards  \n",
       "Model                                                          \n",
       "OLS_Positive     0.0366           0.0426  1.0676          0.0  \n",
       "NNLS_Positive    0.0366           0.0426  1.0676          0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best non-negative model: OLS_Positive  (R²=0.712)\n",
      "\n",
      "Sorted weights (standardized):\n",
      "DOM++            1.3924\n",
      "Bama             1.0676\n",
      "ELU              0.8815\n",
      "40 Time          0.6178\n",
      "BMI              0.3870\n",
      "YPC              0.3520\n",
      "Draft Capital    0.0426\n",
      "Break%           0.0366\n",
      "YCO/A            0.0000\n",
      "Rec Yards        0.0000\n",
      "dtype: float64\n",
      "\n",
      "Saved weights → data/Bakery/_derived/rb_weights_OLS_Positive.csv\n",
      "Saved scaler   → data/Bakery/_derived/rb_scaler.json\n",
      "Saved mapping  → data/Bakery/_derived/rb_feature_mapping.json\n"
     ]
    }
   ],
   "source": [
    "# ===== Reverse-engineer Bakery RB Grade from Bakery_RB_Overall.csv (non-negative weights, no Breakout Age) =====\n",
    "import re, json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import nnls\n",
    "\n",
    "# ---------- config ----------\n",
    "CSV_PATH = Path(\"./data/Bakery/RB/Bakery_RB_Overall.csv\")\n",
    "ROOT = CSV_PATH.parent\n",
    "OUT_DIR = Path(\"./data/Bakery/_derived\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def find_col(frame, candidates):\n",
    "    norm = {re.sub(r\"\\s+\", \"\", c).lower(): c for c in frame.columns}\n",
    "    for cand in candidates:\n",
    "        key = re.sub(r\"\\s+\", \"\", cand).lower()\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    return None\n",
    "\n",
    "def to_num(series):\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = (s.str.replace('%','',regex=False)\n",
    "           .str.replace(r'(?i)round\\s*','',regex=True)\n",
    "           .str.replace(r'(?i)^r\\s*','',regex=True)\n",
    "           .str.replace(r'(?i)(st|nd|rd|th)$','',regex=True)\n",
    "           .str.replace(',','',regex=False)\n",
    "           .str.replace(r'[^0-9\\.\\-]','',regex=True))\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "# canonical features to look for (NO Breakout Age)\n",
    "ALIASES = {\n",
    "    \"DOM++\":        [\"DOM++\",\"DOMpp\",\"DOM_plus_plus\",\"DOMpp_Weighted\",\"DOM\"],\n",
    "    \"40 Time\":      [\"40 Time\",\"Forty\",\"40\"],\n",
    "    \"BMI\":          [\"BMI\"],\n",
    "    \"YPC\":          [\"YPC\",\"Yards per Carry\",\"Yards/Carry\",\"Rushing YPC\"],\n",
    "    \"ELU\":          [\"ELU\",\"Elusiveness\",\"Elusiveness Rating\"],\n",
    "    \"YCO/A\":        [\"YCO/A\",\"YAC/A\",\"Yards After Contact / Att\",\"Yards After Contact per Attempt\"],\n",
    "    \"Break%\":       [\"Break%\",\"Breakaway %\",\"Breakaway Percentage\",\"Breakaway%\"],\n",
    "    \"Draft Capital\":[\"Draft Capital\",\"Draft Cap\",\"Draft Round\",\"Round\",\"Rnd\"],\n",
    "    \"Bama\":         [\"Bama\",\"Bama Rating\",\"BamaAdj\"],\n",
    "    # optional extras if present\n",
    "    \"Shuttle\":      [\"Shuttle\",\"Short Shuttle\",\"20 Shuttle\",\"20 Yard Shuttle\"],\n",
    "    \"Three Cone\":   [\"3 Cone\",\"Three Cone\",\"3-Cone\"],\n",
    "    \"Vertical\":     [\"Vertical\",\"Vertical Jump\"],\n",
    "    \"Broad\":        [\"Broad\",\"Broad Jump\"],\n",
    "    \"Speed Score\":  [\"Speed Score\",\"SpeedScore\"],\n",
    "    \"Rec Yards\":    [\"Receiving Yards\",\"Rec Yds\",\"RecYds\"],\n",
    "    \"Targets\":      [\"Targets\",\"Target Share\",\"Tgt%\"],\n",
    "}\n",
    "TARGET_CANDS = [\"RB Grade\",\"RBGrade\",\"RB_Grade\"]\n",
    "\n",
    "# ---------- load ----------\n",
    "if not CSV_PATH.exists():\n",
    "    # fall back to any similarly named overall file\n",
    "    candidates = list(ROOT.glob(\"Bakery_RB_Overall*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"Could not find {CSV_PATH} or any Bakery_RB_Overall*.csv under {ROOT}\")\n",
    "    CSV_PATH = candidates[0]\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "print(\"Loaded:\", CSV_PATH)\n",
    "print(\"Rows x Cols:\", df.shape)\n",
    "\n",
    "# ---------- map target + features ----------\n",
    "y_col = find_col(df, TARGET_CANDS)\n",
    "if not y_col:\n",
    "    raise ValueError(f\"Could not find RB Grade in columns:\\n{df.columns.tolist()}\")\n",
    "\n",
    "mapped = {feat: find_col(df, alts) for feat, alts in ALIASES.items()}\n",
    "mapped = {k:v for k,v in mapped.items() if v is not None}\n",
    "\n",
    "if not mapped:\n",
    "    raise ValueError(\"No usable feature columns found. Inspect df.columns for header names.\")\n",
    "\n",
    "print(\"\\nUsing features (canonical <- sheet column):\")\n",
    "for k,v in mapped.items():\n",
    "    print(f\"  {k:<12} <- {v}\")\n",
    "\n",
    "X_raw = pd.DataFrame({feat: to_num(df[col]) for feat, col in mapped.items()})\n",
    "y_raw = to_num(df[y_col])\n",
    "\n",
    "# ---------- drop rows with NaN TARGET ----------\n",
    "mask = y_raw.notna()\n",
    "dropped = len(y_raw) - mask.sum()\n",
    "if dropped:\n",
    "    print(f\"\\nDropped {dropped} rows with NaN RB Grade.\")\n",
    "X_raw = X_raw.loc[mask].reset_index(drop=True)\n",
    "y = y_raw.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# ---------- keep columns with enough data (loose thresholds for real-world sheets) ----------\n",
    "keep = [c for c in X_raw.columns if X_raw[c].notna().sum() >= 5 and X_raw[c].nunique(dropna=True) > 1]\n",
    "if not keep:\n",
    "    raise ValueError(\"All candidate features are too sparse/constant. \"\n",
    "                     \"Relax thresholds or ensure the Overall file has those columns filled.\")\n",
    "X_raw = X_raw[keep]\n",
    "print(\"Kept features:\", keep)\n",
    "\n",
    "# ---------- invert where lower is better (NO Breakout Age) ----------\n",
    "for c in [\"40 Time\",\"Draft Capital\",\"Shuttle\",\"Three Cone\"]:\n",
    "    if c in X_raw.columns:\n",
    "        X_raw[c] = -X_raw[c]\n",
    "\n",
    "# ---------- impute X (median) + standardize ----------\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = imp.fit_transform(X_raw)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# final NaN guards\n",
    "if np.isnan(X_scaled).any():\n",
    "    raise ValueError(\"X still contains NaNs after imputation/standardization. Please inspect your data.\")\n",
    "\n",
    "if y.isna().any():\n",
    "    raise ValueError(\"y contains NaNs after filtering; this should not happen.\")\n",
    "\n",
    "# ---------- fit non-negative models ----------\n",
    "results = {}\n",
    "\n",
    "# (A) Positive OLS\n",
    "ols_pos = LinearRegression(positive=True)\n",
    "ols_pos.fit(X_scaled, y)\n",
    "r2_ols = float(ols_pos.score(X_scaled, y)) if y.var() > 0 else float(\"nan\")\n",
    "results[\"OLS_Positive\"] = (r2_ols, pd.Series(ols_pos.coef_, index=X_raw.columns))\n",
    "\n",
    "# (B) NNLS with mean intercept (stable, non-negative)\n",
    "y_mean = float(y.mean())\n",
    "w_nnls, _ = nnls(X_scaled, (y - y_mean).to_numpy())\n",
    "y_pred = y_mean + X_scaled @ w_nnls\n",
    "r2_nnls = float(1 - np.sum((y - y_pred)**2) / np.sum((y - y_mean)**2)) if y.var() > 0 else float(\"nan\")\n",
    "results[\"NNLS_Positive\"] = (r2_nnls, pd.Series(w_nnls, index=X_raw.columns))\n",
    "\n",
    "# ---------- report ----------\n",
    "rows = []\n",
    "for name, (r2, coefs) in results.items():\n",
    "    row = {\"Model\": name, \"R2\": r2}\n",
    "    row.update({f\"w:{k}\": v for k,v in coefs.items()})\n",
    "    rows.append(row)\n",
    "\n",
    "comp = pd.DataFrame(rows).set_index(\"Model\").sort_values(\"R2\", ascending=False)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"\\n=== Model comparison (non-negative only) ===\")\n",
    "display(comp.round(4))\n",
    "\n",
    "best_name = comp.index[0]\n",
    "best_r2, best_coefs = results[best_name]\n",
    "print(f\"\\nBest non-negative model: {best_name}  (R²={best_r2:.3f})\")\n",
    "print(\"\\nSorted weights (standardized):\")\n",
    "print(best_coefs.sort_values(ascending=False).round(4))\n",
    "\n",
    "# ---------- save artifacts for reuse ----------\n",
    "weights_path = OUT_DIR / f\"rb_weights_{best_name}.csv\"\n",
    "scaler_path  = OUT_DIR / \"rb_scaler.json\"\n",
    "meta_path    = OUT_DIR / \"rb_feature_mapping.json\"\n",
    "\n",
    "best_coefs.to_csv(weights_path, header=[\"coef\"])\n",
    "with open(scaler_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"means\": scaler.mean_.tolist(),\n",
    "        \"scales\": scaler.scale_.tolist(),\n",
    "        \"feature_order\": list(X_raw.columns),\n",
    "        \"intercept_mean\": y_mean,\n",
    "        \"model\": best_name\n",
    "    }, f, indent=2)\n",
    "\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump({\"mapped_columns\": mapped, \"kept_features\": keep, \"target\": y_col}, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved weights → {weights_path}\")\n",
    "print(f\"Saved scaler   → {scaler_path}\")\n",
    "print(f\"Saved mapping  → {meta_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc882772-daf4-40c0-a579-27d251c592ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m     97\u001b[39m         model.fit(X_train, y_train)\n\u001b[32m     98\u001b[39m         y_pred = model.predict(X_test)\n\u001b[32m    100\u001b[39m     results.append({\n\u001b[32m    101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m: name,\n\u001b[32m    102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mR2\u001b[39m\u001b[33m\"\u001b[39m: r2_score(y_test, y_pred),\n\u001b[32m    103\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m\"\u001b[39m: mean_absolute_error(y_test, y_pred),\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     })\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# ---------- results ----------\u001b[39;00m\n\u001b[32m    108\u001b[39m comp = pd.DataFrame(results).set_index(\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m).sort_values(\u001b[33m\"\u001b[39m\u001b[33mR2\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ML_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ML_env/lib/python3.11/inspect.py:3195\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3191\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3192\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3193\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3194\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ML_env/lib/python3.11/inspect.py:3184\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3182\u001b[39m         arguments[kwargs_param.name] = kwargs\n\u001b[32m   3183\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3185\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3186\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "# ===== Evaluate Bakery RB Grade with multiple models (train/test split) =====\n",
    "import re, json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.optimize import nnls\n",
    "\n",
    "# ---------- config ----------\n",
    "CSV_PATH = Path(\"./data/Bakery/RB/Bakery_RB_Overall.csv\")\n",
    "\n",
    "ALIASES = {\n",
    "    \"DOM++\":        [\"DOM++\",\"DOMpp\",\"DOM_plus_plus\",\"DOMpp_Weighted\",\"DOM\"],\n",
    "    \"40 Time\":      [\"40 Time\",\"Forty\",\"40\"],\n",
    "    \"BMI\":          [\"BMI\"],\n",
    "    \"YPC\":          [\"YPC\",\"Yards per Carry\",\"Yards/Carry\",\"Rushing YPC\"],\n",
    "    \"ELU\":          [\"ELU\",\"Elusiveness\",\"Elusiveness Rating\"],\n",
    "    \"YCO/A\":        [\"YCO/A\",\"YAC/A\",\"Yards After Contact / Att\",\"Yards After Contact per Attempt\"],\n",
    "    \"Break%\":       [\"Break%\",\"Breakaway %\",\"Breakaway Percentage\",\"Breakaway%\"],\n",
    "    \"Draft Capital\":[\"Draft Capital\",\"Draft Cap\",\"Draft Round\",\"Round\",\"Rnd\"],\n",
    "    \"Bama\":         [\"Bama\",\"Bama Rating\",\"BamaAdj\"],\n",
    "}\n",
    "TARGET_CANDS = [\"RB Grade\",\"RBGrade\",\"RB_Grade\"]\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def find_col(frame, candidates):\n",
    "    norm = {re.sub(r\"\\s+\", \"\", c).lower(): c for c in frame.columns}\n",
    "    for cand in candidates:\n",
    "        key = re.sub(r\"\\s+\", \"\", cand).lower()\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    return None\n",
    "\n",
    "def to_num(series):\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = (s.str.replace('%','',regex=False)\n",
    "           .str.replace(r'(?i)round\\s*','',regex=True)\n",
    "           .str.replace(r'(?i)^r\\s*','',regex=True)\n",
    "           .str.replace(r'(?i)(st|nd|rd|th)$','',regex=True)\n",
    "           .str.replace(',','',regex=False)\n",
    "           .str.replace(r'[^0-9\\.\\-]','',regex=True))\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "# ---------- load data ----------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "y_col = find_col(df, TARGET_CANDS)\n",
    "mapped = {feat: find_col(df, alts) for feat, alts in ALIASES.items()}\n",
    "mapped = {k:v for k,v in mapped.items() if v is not None}\n",
    "\n",
    "X_raw = pd.DataFrame({feat: to_num(df[col]) for feat, col in mapped.items()})\n",
    "y_raw = to_num(df[y_col])\n",
    "\n",
    "# drop NaN target\n",
    "mask = y_raw.notna()\n",
    "X_raw, y_raw = X_raw.loc[mask], y_raw.loc[mask]\n",
    "\n",
    "# invert where lower = better\n",
    "for c in [\"40 Time\",\"Draft Capital\"]:\n",
    "    if c in X_raw.columns:\n",
    "        X_raw[c] = -X_raw[c]\n",
    "\n",
    "# impute + scale\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_imp = imp.fit_transform(X_raw)\n",
    "X_scaled = scaler.fit_transform(X_imp)\n",
    "\n",
    "# ---------- train/test split ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_raw, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ---------- models ----------\n",
    "models = {\n",
    "    \"OLS_Positive\": LinearRegression(positive=True),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.01, max_iter=5000),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"NNLS_Positive\": \"custom\"  # handled separately\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# fit sklearn models\n",
    "for name, model in models.items():\n",
    "    if name == \"NNLS_Positive\":\n",
    "        w, _ = nnls(X_train, y_train - y_train.mean())\n",
    "        y_pred = y_train.mean() + X_test @ w\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"R2\": r2_score(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"RMSE\": mean_squared_error(y_test, y_pred, squared=False)\n",
    "    })\n",
    "\n",
    "# ---------- results ----------\n",
    "comp = pd.DataFrame(results).set_index(\"Model\").sort_values(\"R2\", ascending=False)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(comp.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3c373-f374-4e6b-a219-9268597bc000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
