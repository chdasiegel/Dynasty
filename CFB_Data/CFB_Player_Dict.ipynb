{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37dec755-db01-40f8-b1b8-9e45703652f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'player'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/x7/zdg0t2zd0t75tgrfx63fhv7m0000gn/T/ipykernel_3295/2374276479.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;28;01min\u001b[39;00m stat_dfs:\n\u001b[32m     28\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'player'\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m df.columns \u001b[38;5;28;01mand\u001b[39;00m \u001b[33m'Player'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m df.columns:\n\u001b[32m     29\u001b[39m                 df.rename(columns={\u001b[33m'Player'\u001b[39m: \u001b[33m'player'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     30\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         merged = reduce(\u001b[38;5;28;01mlambda\u001b[39;00m left, right: pd.merge(left, right, on=[\u001b[33m'player'\u001b[39m, \u001b[33m'season'\u001b[39m], how=\u001b[33m'outer'\u001b[39m), stat_dfs)\n\u001b[32m     32\u001b[39m         combined_data.append(merged)\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Combine all years\u001b[39;00m\n",
      "\u001b[32m/var/folders/x7/zdg0t2zd0t75tgrfx63fhv7m0000gn/T/ipykernel_3295/2374276479.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         merged = reduce(\u001b[38;5;28;01mlambda\u001b[39;00m left, right: pd.merge(left, right, on=[\u001b[33m'player'\u001b[39m, \u001b[33m'season'\u001b[39m], how=\u001b[33m'outer'\u001b[39m), stat_dfs)\n",
      "\u001b[32m/opt/miniconda3/envs/ML_env/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    106\u001b[39m     copy: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    107\u001b[39m     indicator: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    108\u001b[39m     validate: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    109\u001b[39m ) -> DataFrame:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     op = _MergeOperation(\n\u001b[32m    111\u001b[39m         left,\n\u001b[32m    112\u001b[39m         right,\n\u001b[32m    113\u001b[39m         how=how,\n",
      "\u001b[32m/opt/miniconda3/envs/ML_env/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    699\u001b[39m         (\n\u001b[32m    700\u001b[39m             self.left_join_keys,\n\u001b[32m    701\u001b[39m             self.right_join_keys,\n\u001b[32m    702\u001b[39m             self.join_names,\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    704\u001b[39m \n\u001b[32m    705\u001b[39m         \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[32m    706\u001b[39m         \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n",
      "\u001b[32m/opt/miniconda3/envs/ML_env/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1158\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1159\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1160\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1161\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1163\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1164\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1165\u001b[39m                             right_keys.append(right.index)\n",
      "\u001b[32m/opt/miniconda3/envs/ML_env/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1846\u001b[39m                 .get_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   1847\u001b[39m                 ._values\n\u001b[32m   1848\u001b[39m             )\n\u001b[32m   1849\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1850\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1851\u001b[39m \n\u001b[32m   1852\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1853\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'player'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set working directory if needed\n",
    "# os.chdir(\"/path/to/csvs\")\n",
    "\n",
    "years = list(range(2016, 2025))\n",
    "stats = [\"passing\", \"rushing\", \"receiving\"]\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for year in years:\n",
    "    stat_dfs = []\n",
    "    \n",
    "    for stat in stats:\n",
    "        file_name = f\"{year}_{stat}.csv\"\n",
    "        if os.path.exists(file_name):\n",
    "            df = pd.read_csv(file_name)\n",
    "            df['season'] = year\n",
    "            df['stat_type'] = stat\n",
    "            stat_dfs.append(df)\n",
    "    \n",
    "    # Merge all stat types on 'player' and 'season'\n",
    "    if stat_dfs:\n",
    "        from functools import reduce\n",
    "        # Standardize column name\n",
    "        for df in stat_dfs:\n",
    "            if 'player' not in df.columns and 'Player' in df.columns:\n",
    "                df.rename(columns={'Player': 'player'}, inplace=True)\n",
    "\n",
    "        merged = reduce(lambda left, right: pd.merge(left, right, on=['player', 'season'], how='outer'), stat_dfs)\n",
    "        combined_data.append(merged)\n",
    "\n",
    "# Combine all years\n",
    "final_df = pd.concat(combined_data, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(\"cfb_combined_stats_2016_2024.csv\", index=False)\n",
    "print(\"âœ… Combined CSV saved as cfb_combined_stats_2016_2024.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5db6a-a91d-42fa-a381-8278af701ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e0102-89af-4a3f-9cd6-2bb9a20984a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
